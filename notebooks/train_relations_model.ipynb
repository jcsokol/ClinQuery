{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7904f2-4270-49a0-9e1e-bc064999eb2e",
   "metadata": {},
   "source": [
    "# Train relations model\n",
    "\n",
    "This notebook shows the workflow I used to fine-tune the relations model of the end-to-end clinical reasoning engine. Some tweaks have been left out; contact me if you want to go into every detail as to how I trained it.\n",
    "\n",
    "**Data:** synthetic, de-identified examples in `./db/training_data.jsonl`  \n",
    "**Model base:** `michiyasunaga/BioLinkBERT-large`  \n",
    "**Outputs:** checkpoints stored to `../pipeline_ingest/db/relations_model`, sample predictions stored to `./db/example_predictions.jsonl`\n",
    "\n",
    "All used EHR notes are synthetic; no real patient data was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb55ab33-a867-4f8f-a3e7-efa412001459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    AutoModel\n",
    ")\n",
    "from relations_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c781beeb-e62a-4101-b5f5-787448cb2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# make sure GPU is available\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec905b18-c517-482f-8a06-70dd7ad530f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3746, 1023]\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = 'michiyasunaga/BioLinkBERT-large'\n",
    "config = AutoConfig.from_pretrained(model_name,num_labels=3,hidden_dropout_prob=0.2,attention_probs_dropout_prob=0.2) # use 0.2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "model = model.to(device)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit([\"TIME_RELATION\", \"NEGATION_RELATION\", \"NO_RELATION\"])\n",
    "data_trainset, data_devset = load_train_and_devsets_from_jsonl('/scratch/users/jsokol/escalation_project/data/extractions/batch2/batch2_prodigy_and_gpt_annotations_v4_manuallycorrected_fixed_formatting.jsonl',True,4)\n",
    "data_trainset = prepare_relation_examples_with_chunking(data_trainset, tokenizer, label_encoder, overlap=0.25, max_positives_token_distance=100, max_control_token_distance=30, max_control_token_distance_lr=100, lr_controls_prop=0.25) \n",
    "data_devset = prepare_relation_examples_with_chunking(data_devset, tokenizer, label_encoder, overlap=0.25, max_positives_token_distance=100, max_control_token_distance=30, max_control_token_distance_lr=100, lr_controls_prop=0.25) \n",
    "\n",
    "# compute weighting scheme to feed to trainer\n",
    "label_counts = Counter(data_trainset['labels'])\n",
    "num_classes = len(label_counts)\n",
    "total = sum(label_counts.values())\n",
    "weights = torch.tensor([\n",
    "    total / (label_counts.get(i, 1)) for i in range(num_classes)\n",
    "], dtype=torch.float)\n",
    "\n",
    "print([len(data_trainset),len(data_devset)])\n",
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9996789f-5653-4d34-bc4a-9fb2ec34c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect token distance distributions for each label\n",
    "# import matplotlib.pyplot as plt\n",
    "# dist_list = [data_trainset[i]['distance'] for i in range(3700) if data_trainset[i]['labels']==2]\n",
    "# dist_list = [data_devset[i]['distance'] for i in range(len(data_devset)) if data_devset[i]['labels']==2]\n",
    "# plt.hist(dist_list)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e550447-af18-42ef-b2fe-6c663510f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few examples to see if they are formatted correctly\n",
    "# example_i = 296\n",
    "# id2labels = {0:'NEGATION_RELATION',1:'NO_RELATION',2:'TIME_RELATION'}\n",
    "# print(id2labels[data_trainset[example_i]['labels']])\n",
    "# print(data_trainset[example_i]['distance'])\n",
    "# print(data_trainset[example_i]['debug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dac2609-4a63-42a8-9398-b8fa548ae9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../pipeline_ingest/db/relations_model\",\n",
    "    learning_rate=5e-6, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20, \n",
    "    gradient_accumulation_steps=4,  # use 4-1\n",
    "    warmup_steps=800, # use 800 \n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1000,\n",
    "    weight_decay = 0.05, # use 0.1-0.05\n",
    "    max_grad_norm = 1.0,\n",
    "    lr_scheduler_type='cosine', \n",
    "    label_smoothing_factor=0.2, # 0.2-0.4\n",
    "    fp16=True, # use for gatortron\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_trainset,\n",
    "    eval_dataset=data_devset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)], # use 2-3\n",
    "    compute_metrics=compute_metrics_with_confusion_matrix,\n",
    "    class_weights=weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916b5480-85b2-4a70-9a20-73567595cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "563476e1-52ad-45da-8570-7c206c3625be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NEGATION_RELATION', 1: 'NO_RELATION', 2: 'TIME_RELATION'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8485    0.9180        33\n",
      "           1     0.9572    0.9468    0.9520       733\n",
      "           2     0.8687    0.9085    0.8881       284\n",
      "\n",
      "    accuracy                         0.9333      1050\n",
      "   macro avg     0.9420    0.9012    0.9194      1050\n",
      "weighted avg     0.9346    0.9333    0.9336      1050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3981826603412628,\n",
       " 'eval_model_preparation_time': 0.0067,\n",
       " 'eval_accuracy': 0.9333333333333333,\n",
       " 'eval_confusion_matrix_0_0': 28,\n",
       " 'eval_confusion_matrix_0_1': 5,\n",
       " 'eval_confusion_matrix_0_2': 0,\n",
       " 'eval_confusion_matrix_1_0': 0,\n",
       " 'eval_confusion_matrix_1_1': 694,\n",
       " 'eval_confusion_matrix_1_2': 39,\n",
       " 'eval_confusion_matrix_2_0': 0,\n",
       " 'eval_confusion_matrix_2_1': 26,\n",
       " 'eval_confusion_matrix_2_2': 258,\n",
       " 'eval_runtime': 8.0749,\n",
       " 'eval_samples_per_second': 130.032,\n",
       " 'eval_steps_per_second': 8.173}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model using devset\n",
    "print({0:'NEGATION_RELATION',1:'NO_RELATION',2:'TIME_RELATION'})\n",
    "# trainer.evaluate(eval_dataset=data_trainset)\n",
    "trainer.evaluate(eval_dataset=data_devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea46c8b-30e3-4fc4-b4ce-2df2c56b60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save/load model\n",
    "# output_dir = \"../pipeline_ingest/db/relations_model\"\n",
    "# trainer.save_model(output_dir) \n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a759875-bee9-4e0f-8203-e14910dc1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a few predictions and inspect them\n",
    "id2labels = {0:'NEGATION_RELATION',1:'NO_RELATION',2:'TIME_RELATION'}\n",
    "label2id = {v: k for k, v in id2labels.items()}\n",
    "jsonl_input_path = './db/training_data.jsonl'\n",
    "jsonl_output_path = './db/example_predictions.jsonl'\n",
    "allowed_relations = [(\"C_ENT\", \"TIME\", \"TIME_RELATION\"),(\"TABLE\", \"TIME\", \"TIME_RELATION\"),(\"C_ENT\", \"NEGATION\", \"NEGATION_RELATION\")]\n",
    "with open(jsonl_input_path, \"r\") as f:\n",
    "    entries = [json.loads(line) for line in f]\n",
    "with open(jsonl_output_path, \"w\") as out_f:\n",
    "    for entry in entries[:5]: ### set how many notes to generate predictions over ###\n",
    "        counter += 1\n",
    "        text = entry[\"text\"]\n",
    "        spans = entry.get(\"spans\", [])\n",
    "        relations, xml_tagged_texts, xml_tagged_texts_no_relations = predict_relations_with_chunking(text,spans,model,tokenizer,label2id,id2labels,allowed_relations,device,prob_threshold=0.9,max_token_distance=100)\n",
    "        relations_filtered = filter_relations_for_predictions(relations)\n",
    "        output = {\"text\": text, \"spans\": spans, \"relations\": relations_filtered}\n",
    "        out_f.write(json.dumps(output) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4544023d-4bc7-4b10-bf28-96c89b8b790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATION_RELATION', 'TIME_RELATION'], dtype='<U17'), array([ 9, 74]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show relative counts of predicted negation/time relations\n",
    "np.unique([relations_filtered[i]['label'] for i in range(len(relations_filtered))],return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee545cd-75a9-43f3-8880-877eba84d361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "**Patient Name:** Harold Hilll  \n",
      "**MRN:** [Redacted]  \n",
      "**DOB:** 03/24/1993  \n",
      "**Sex:** Male  \n",
      "**Admit Date:** 2024-04-13  \n",
      "**Attending:** Dr. K. Adams  \n",
      "**Location:** MICU, Bed 7  \n",
      "**Consults:** Cardiology, Infectious Disease, PT/OT  \n",
      "**Allergies:** NKDA  \n",
      "**Code Status:** Full Code  \n",
      "**Height:** 172 cm  \n",
      "**Weight:** 81 kg  \n",
      "**BMI:** 27.3 kg/m2  \n",
      "\n",
      "---\n",
      "\n",
      "### Chief Complaint\n",
      "Progressive dyspnea, orthopnea, lower extremity edema.\n",
      "\n",
      "---\n",
      "\n",
      "### HPI\n",
      "Mr. Harold Hilll is a 31-year-old male with a history of acute viral pharyngitis and recent right ankle sprain, presenting with 1 week of worsening shortness of breath, orthopnea, and bilateral leg swelling. He initially attributed symptoms to his viral illness and limited mobility. On the <CHILD>day of admission</CHILD>, he developed acute chest discomfort and <HEAD>near-syncope</HEAD>. EMS noted hypotension (SBP 72 mmHg), tachycardia, and hypoxia. He was emergently transferred to the ICU for presumed cardiogenic shock.  \n",
      "\n",
      "Past 24 hours:  \n",
      "- Intubated for hypoxemic respiratory failure  \n",
      "- Started on norepinephrine, dobutamine  \n",
      "- Bedside echo: severe global LV dysfunction, LVEF ~15%, moderate MR, RV mildly reduced  \n",
      "- Emergent placement of percutaneous LVAD (Impella CP) due to refractory shock  \n",
      "\n",
      "---\n",
      "\n",
      "### Past Medical History\n",
      "- Acute viral pharyngitis (self-limited, multiple episodes)\n",
      "- Right ankle sprain (recent, immobilized)\n",
      "- No prior cardiac history\n",
      "- No DM, HTN, CKD, or known hyperlipidemia\n",
      "\n",
      "### Past Surgical History\n",
      "- None\n",
      "\n",
      "### Family History\n",
      "- No known premature CAD or sudden cardiac death\n",
      "- Father: healthy, age 61\n",
      "- Mother: hypothyroidism\n",
      "\n",
      "### Social History\n",
      "- Lives alone, works as accountant\n",
      "- Denies tobacco, rare EtOH, no illicit drug use\n",
      "\n",
      "---\n",
      "\n",
      "### Medications on Admission\n",
      "- Naproxen sodium 220 mg PRN (for ankle sprain)\n",
      "- No home cardiac meds\n",
      "\n",
      "---\n",
      "\n",
      "### ICU Course Summary\n",
      "\n",
      "**Day 0 (Admission):**  \n",
      "- Profound shock, intubation, started on vasopressors/inotropes  \n",
      "- Bedside echo: severe LV dysfunction, likely viral myocarditis  \n",
      "- Emergent Impella CP placed for hemodynamic support  \n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# spot check predicted relation\n",
    "print(xml_tagged_texts[10]) # positive example (i.e. predicted negation/time relation)\n",
    "# print(xml_tagged_texts_no_relations[10]) # negative example (i.e. predicted no relation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5fc57-74b7-4d34-804d-3828a17bd74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8a62e-7c3c-47f7-bab0-3ad19b5e7914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46341a4-73e8-490b-b937-0e546f27fd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinquery_environment-gpu-linux",
   "language": "python",
   "name": "clinquery_environment-gpu-linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
